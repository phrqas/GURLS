----------------------------------------------------------
--------   Automated benchmarking for pyGURLS    ---------
----------------------------------------------------------

Table of Contents
=================

- Introduction
- Dependencies
- Configuration

Introduction
============

This is an automated benchmarking module for pyGURLS, which allows
learning algorithms to be specified separate from the different
types of data on which they should be run. Configuration is done
through a simple text file, from which all benchmarking code is 
automatically generated.

Dependencies
============

Before running any benchmarks, make sure that pyGURLS has been correctly
built and that the pygurls module is in your PYTHONPATH (see pyGURLS 
installation instructions for details). Currently, the benchmarking module 
only depends on scikit-learn, a popular and thorough collection of machine 
learning packages available in Python (see http://scikit-learn.org/stable/).

The recommended way to install scikit-learn on your system is by using pip:

    $ sudo pip install -U scikit-learn

Configuration
=============

Setting up a new data set
-------------------------

The datasets/ folder is recursively crawled for available data sets. In order
to add a new data set, do the following:

    1. Create a new folder within datasets/.

    2. Add your data to that folder.

    3. Add a file called pre_process*.py to the folder, where * can stand for any 
    string. This script is responsible for reading the data in the folder and 
    generating a Matlab .mat file containing the standard names

        - Xtrain -> inputs for training.
        - Ytrain -> outputs for training.
        - Xtest -> inputs for testing.
        - Ytest -> outputs for testing.

The pre_process*.py scripts are automatically executed by the benchmarking module
in order to generate the .mat files, or skipped should the .mat file already
exist.

Setting up a new test
---------------------

Learning algorithms should be defined in the file bench_tests.py with the following
syntax:

    def learn_alg_name(Xtrain,Ytrain,Xtest,Ytest,*args,**kwargs):
        #Insert the code for the learning function
        return accuracy

where 'learn_alg_name' can be any valid function name in Python. The inputs are 
automatically generated by the benchmarking module, so you only need to make sure
that the function returns its accuracy on the test set.

Configuring a new benchmarking session
--------------------------------------

A benchmarking session is configured using config_benchmarks.txt. Its syntax is
very simple:

    <test_func_name> <n-runs> <ds1> <ds2> ... | _all_

where 

    <test_func_name>    -> name of a learning function defined in bench_tests.py
    <n-runs>            -> number of times the test should be run
    <ds1> <ds2> ...     -> list of datasets on which to run the learning function

Alternatively, you can use the word _all_ instead of a list of data sets to
specify that a learning function should be tested with all available data sets.

Running the benchmarks
----------------------

Running the benchmarks with default options (configurations in
config_benchmarks.txt, skip pre-processing of data sets whose .mat files have
already been generated) is very easy as well! 

    1. First, go to the benchmark folder;

        $ cd <GURLS-HOME>/pygurls/benchmarks
    
    2. Use 'bench_gen.py' to generate the benchmarking script 'bench_run.py';
    
        $ python bench_gen.py

    3. Run the benchmark;

        $ python bench_run.py

All results (accuracy on testing set and elapsed time) will be recorded in the
results/ folder in a file called 'benchmark_results_%m_%d_%y-%H_%M_%S.txt'.
In addition to the text file, all benchmarking results are also recorded in 
the nested dictionary 'benchmark_results', which can be retrieved from within 
a Python console. For instance, if you are using iPython, this is how you can 
print the benchmarking results:

    $ ipython
    In [1]: %run bench_run.py
    In [2]: benchmark_results

The 'benchmark_results' dictionary can be used for plotting and other 
post-processing tasks.
